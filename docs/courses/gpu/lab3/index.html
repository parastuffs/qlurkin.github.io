<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU in Rust - Game Of Life</title>
    <script src="/document.js" defer></script>
    
</head>
<body>
    <h1>WebGPU in Rust <small>Game Of Life</small></h1>
    
    <h2>Introduction</h2>
<p><strong>This lab is a Rust version of a Javascript Codelab available <a href="https://codelabs.developers.google.com/your-first-webgpu-app">here</a>. Most of the Rust specific parts are heavily inspired from <a href="https://sotrh.github.io/learn-wgpu/">here</a>.</strong></p>
<p>WebGPU is a new, modern API for accessing the capabilities of your GPU in web apps. But WebGPU is designed to be used beyond web apps. It is an excellent choice for authoring cross-platform GPU accelerated app.</p>
<p>In this lab, you build <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway&#39;s Game of Life</a> using WebGPU. The Game of Life is what&#39;s known as a cellular automaton, in which a grid of cells change state over time based on some set of rules. In the Game of Life cells become active or inactive depending on how many of their neighboring cells are active, which leads to interesting patterns that fluctuate as you watch.</p>
<h2>Project Setup</h2>
<p>We will begin by setup our Rust project:</p>
<div class="terminal">
  > cargo new my_project_name
  > cd my_project_name
</div>

<p>To create a WebGPU app in Rust, we will need two crates:</p>
<ul>
<li><code>wgpu</code>: which is an Rust implmentation of the WebGPU standard,</li>
<li><code>winit</code>: which let you open application windows and deal with input events.</li>
<li><code>log</code> and <code>env_logger</code>: to get nice <code>wgpu</code> runtime error messages.</li>
</ul>
<p>So we add these crates in our dependencies (<code>Cargo.toml</code>):</p>
<pre><code class="language-toml">[package]
name = &quot;gpu_game_of_life&quot;
version = &quot;0.1.0&quot;
edition = &quot;2021&quot;

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
wgpu = &quot;0.17&quot;
winit = &quot;0.28&quot;
log = &quot;0.4&quot;
env_logger = &quot;0.10&quot;
</code></pre>
<h2>Create a Window</h2>
<p>Here&#39;s a simple example of how to use <code>winit</code> to create a window:</p>
<pre><code class="language-rust">use winit::{
    event::{Event, WindowEvent},
    event_loop::EventLoop,
    window::WindowBuilder,
};

pub fn start() {
  let event_loop = EventLoop::new();
  let window = WindowBuilder::new().build(&amp;event_loop).unwrap();

  event_loop.run(move |event, _, control_flow| {
    // ControlFlow::Poll continuously runs the event loop, even if the OS hasn&#39;t
    // dispatched any events. This is ideal for games and similar applications.
    control_flow.set_poll();

    match event {
      Event::WindowEvent {
        ref event,
        window_id,
      } if window_id == window.id() =&gt; {
        match event {
          WindowEvent::CloseRequested =&gt; {
            println!(&quot;The close button was pressed; stopping&quot;);
            control_flow.set_exit();
          }
          _ =&gt; {}
        }
      },
      Event::MainEventsCleared =&gt; {
        // Application update code.

        // Queue a RedrawRequested event.
        window.request_redraw();
      },
      Event::RedrawRequested(_) =&gt; {
        // Redraw the application.
      },
      _ =&gt; ()
    }
  });
}

fn main() {
  env_logger::init();
  start();
}
</code></pre>
<p>The <code>event_loop</code> will run the closure <code>|event, _, control_flow| { ... }</code> for all events. In this example, we deal with three kind of events:</p>
<ul>
<li><code>MainEventsCleared</code>: Emitted when all of the event loop’s input events have been processed. This event is useful if you want to do stuff that happens as the “main body” of your event loop.</li>
<li><code>RedrawRequested</code>: which happens each time a redraw is requested by the OS or by our code with <code>window.request_redraw()</code>,</li>
<li><code>WindowEvent</code>: which can be of different types. Here, we only look for <code>CloseRequested</code> which happens when we close the window.</li>
</ul>
<p>It is very important to enable logging via <code>env_logger::init()</code>. When wgpu hits any error it panics with a generic message, while logging the real error via the log crate. This means if you don&#39;t include <code>env_logger::init()</code>, wgpu will fail silently, leaving you very confused! This has been done at the beginning of the <code>main()</code> function. </p>
<h2>The <code>window</code> module</h2>
<p>To keep our code organized, we&#39;ll divide it into several modules. We&#39;ll put our <code>start()</code> function in a new module called <code>window</code>. First we declare the module in the <code>main.rs</code> file:</p>
<pre><code class="language-rust">mod window
</code></pre>
<p>Then we create a new a new file named <code>window.rs</code> and we put the <code>start()</code> function in it. To make our function accessible outside the module we must declare it as public.</p>
<pre><code class="language-rust">use winit::{
    event::{Event, WindowEvent},
    event_loop::EventLoop,
    window::WindowBuilder,
};

pub fn start() {
  //...
}
</code></pre>
<p>To use the function in our <code>main.rs</code> we need to bring it into the scope with a <code>use</code> statement. So in the <code>main.rs</code> file we add:</p>
<pre><code class="language-rust">use crate::window::start;
</code></pre>
<p>Now our <code>main.rs</code> look like this:</p>
<pre><code class="language-rust">mod window;

use crate::window::start;

fn main() {
  env_logger::init();
  start();
}
</code></pre>
<h2>The surface</h2>
<p>To use our GPU, we need tu create a <code>Device</code>, a <code>Queue</code>, a <code>Surface</code> and multiple other things. To keep all these handles, we&#39;ll create a <code>struct</code> named <code>Context</code> in the <code>window.rs</code> file.</p>
<pre><code class="language-rust">use winit::window::Window;

pub struct Context {
  surface: wgpu::Surface,
  device: wgpu::Device,
  queue: wgpu::Queue,
  config: wgpu::SurfaceConfiguration,
  size: winit::dpi::PhysicalSize&lt;u32&gt;,
  // The window must be declared after the surface so
  // it gets dropped after it as the surface contains
  // unsafe references to the window&#39;s resources.
  window: Window,
}
</code></pre>
<p>To create a <code>Context</code>, let&#39;s create a <code>new</code> method for it:</p>
<pre><code class="language-rust">impl Context {
  // Creating some of the wgpu types requires async code
  pub async fn new(window: Window) -&gt; Self {
    let size = window.inner_size();

    // The instance is the context for all other wgpu objects.
    // Backends::all =&gt; Vulkan + Metal + DX12
    let instance = wgpu::Instance::new(wgpu::InstanceDescriptor {
      backends: wgpu::Backends::all(),
      dx12_shader_compiler: Default::default(),
    });
    
    // # Safety
    //
    // The surface needs to live as long as the window that created it.
    // State owns the window so this should be safe.
    let surface = unsafe { instance.create_surface(&amp;window) }.unwrap();

    // The adapter is a handle to a physical graphics and/or compute device.
    let adapter = instance.request_adapter(
      &amp;wgpu::RequestAdapterOptions {
        power_preference: wgpu::PowerPreference::default(),
        compatible_surface: Some(&amp;surface),
        force_fallback_adapter: false,
      },
    ).await.unwrap();

    // The Device is an open connection to a graphics and/or compute device.
    // The Queue is a handle to a command queue on a device.
    let (device, queue) = adapter.request_device(
      &amp;wgpu::DeviceDescriptor {
        features: wgpu::Features::empty(),
        limits: wgpu::Limits::default(),
        label: None,
      },
      None, // Trace path
    ).await.unwrap();

    let surface_caps = surface.get_capabilities(&amp;adapter);
    // Shader code in this tutorial assumes an sRGB surface texture. Using a
    // different one will result all the colors coming out darker. If you want
    // to support non sRGB surfaces, you&#39;ll need to account for that when
    // drawing to the frame.
    let surface_format = surface_caps.formats.iter()
      .copied()
      .find(|f| f.is_srgb())            
      .unwrap_or(surface_caps.formats[0]);
    let config = wgpu::SurfaceConfiguration {
      usage: wgpu::TextureUsages::RENDER_ATTACHMENT,
      format: surface_format,
      width: size.width,
      height: size.height,
      present_mode: surface_caps.present_modes[0],
      alpha_mode: surface_caps.alpha_modes[0],
      view_formats: vec![],
    };
    surface.configure(&amp;device, &amp;config);

    Self {
      window,
      surface,
      device,
      queue,
      config,
      size,
    }
  }
}
</code></pre>
<p>Now we can create our <code>Context</code> in the <code>start()</code> function:</p>
<pre><code class="language-rust">pub async fn start() {
  // Window setup...

  let mut context = Context::new(window).await;

  // Event loop...
}
</code></pre>
<p>At this point we get a borrowing error because <code>window</code> has moved into the <code>Context</code> and we can no longer use it in our event loop. We just need to use the <code>window</code> inside the <code>Context</code> instead in:</p>
<pre><code class="language-rust">Event::MainEventsCleared =&gt; {
  context.window.request_redraw();
},
</code></pre>
<p>and in:</p>
<pre><code class="language-rust">Event::WindowEvent {
    ref event,
    window_id,
} if window_id == context.window.id() =&gt; {
  // ...
}
</code></pre>
<p>The <code>start()</code> function must become <code>async</code> because it call the <code>Context::new()</code> that is <code>async</code>. To run <code>start()</code> in our <code>main()</code> function we need to use a crate that is able to await future. We will use <code>pollster</code> so let&#39; add it to our <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
# other deps...
pollster = &quot;0.3&quot;
</code></pre>
<p>We can now update the <code>main()</code> to use <code>pollster</code>:</p>
<pre><code class="language-rust">fn main() {
  env_logger::init();
  pollster::block_on(start());
}
</code></pre>
<p>If we want to support resizing in our application, we&#39;re going to need to reconfigure the surface every time the window&#39;s size changes. That&#39;s the reason we stored the physical size and the config used to configure the surface. With all of these, we can add a resize method to our <code>Context</code>:</p>
<pre><code class="language-rust">pub fn resize(&amp;mut self, new_size: winit::dpi::PhysicalSize&lt;u32&gt;) {
  if new_size.width &gt; 0 &amp;&amp; new_size.height &gt; 0 {
    self.size = new_size;
    self.config.width = new_size.width;
    self.config.height = new_size.height;
    self.surface.configure(&amp;self.device, &amp;self.config);
  }
}
</code></pre>
<p>And we can call it when we get a <code>Resized</code> event or a <code>ScaleFactorChanged</code> event in our event loop:</p>
<pre><code class="language-rust">// ...
match event {
    Event::WindowEvent {
        ref event,
        window_id,
    } if window_id == context.window.id() =&gt; {
        match event {
            WindowEvent::CloseRequested =&gt; {
                println!(&quot;The close button was pressed; stopping&quot;);
                control_flow.set_exit();
            },
            WindowEvent::Resized(physical_size) =&gt; {
                println!(&quot;Scaling Window&quot;);
                context.resize(*physical_size);
            },
            WindowEvent::ScaleFactorChanged { new_inner_size, .. } =&gt; {
                println!(&quot;Scale Factor Changed&quot;);
                context.resize(**new_inner_size);
            },
            _ =&gt; {}
        }
    },
    // other events
</code></pre>
<h2>Our App</h2>
<p>All the previous code is actually boilerplate not specific to our application. We will put the code of our app in a separate module named <code>app</code>. So we declare the module in <code>main.rs</code> and we add a <code>app.rs</code> file with:</p>
<pre><code class="language-rust">pub struct App {

}

impl App {
  pub fn new(context: &amp;mut Context) -&gt; Self {
    Self {

    }
  }

  fn input(&amp;mut self, event: &amp;WindowEvent) -&gt; bool {
    return false;  // means that the event must be handeld in the start() function
  }

  fn update(&amp;mut self) {

  }

  fn render(&amp;mut self, context: &amp;mut Context) -&gt; Result&lt;(), wgpu::SurfaceError&gt; {

  }
}
</code></pre>
<p>The <code>new()</code> method will act as a constructor. The <code>input()</code> method will get events to let us react to user&#39;s inputs. The <code>update()</code> method will comtain the simulation logic. And the <code>render()</code> method will eb in charge of rendering the frame.</p>
<p>We will create the <code>App</code> and call its methods in the <code>start()</code> function:</p>
<pre><code class="language-rust">use crate::app::App;
// ...

pub async fn start() {
  // ...
  
  let mut context = Context::new(window).await;
  let mut app = App::new(&amp;mut context);

  event_loop.run(move |event, _, control_flow| {
    control_flow.set_poll();

    match event {
      Event::WindowEvent {
        ref event,
        window_id,
      } if window_id == context.window.id() =&gt; {
        if !app.input(event) {
          match event {
            // ...
          }
        }
      },
      // ...
      Event::RedrawRequested(_) =&gt; {
        app.update();
        match app.render(&amp;mut context) {
          Ok(_) =&gt; {}
          // Reconfigure the surface if lost
          Err(wgpu::SurfaceError::Lost) =&gt; context.resize(context.size),
          // The system is out of memory, we should probably quit
          Err(wgpu::SurfaceError::OutOfMemory) =&gt; {
            eprintln!(&quot;Out Of Memory&quot;);
            control_flow.set_exit()
          }
          // All other errors (Outdated, Timeout) should be resolved by
          // the next frame
          Err(e) =&gt; eprintln!(&quot;{:?}&quot;, e),
        }
      }
      _ =&gt; (),
    }
  });
}
</code></pre>
<p>With this, all the methods of our <code>App</code> will be called at the right moment !</p>
<p>We have pass the <code>Context</code> to our <code>new()</code> method. It&#39;s because we will need multiple fieldof it. The problem is that none of these fields are public. So let&#39;s add some getters to our <code>Context</code> struct:</p>
<pre><code class="language-rust">impl Context {
 // ...
 pub fn window(&amp;self) -&gt; &amp;Window {
    &amp;self.window
  }

  pub fn surface(&amp;self) -&gt; &amp;wgpu::Surface {
    &amp;self.surface
  }

  pub fn device(&amp;self) -&gt; &amp;wgpu::Device {
    &amp;self.device
  }

  pub fn queue(&amp;self) -&gt; &amp;wgpu::Queue {
    &amp;self.queue
  }

  pub fn config(&amp;self) -&gt; &amp;wgpu::SurfaceConfiguration {
    &amp;self.config
  }
}
</code></pre>
<h2>First render</h2>
<p>To render something, we need to send commands with the command queue. These commands are grouped into <strong>Render Pass</strong>. The target of the render is a texture (an image) but we can&#39;t directly render to the texture. We must render to a View of the texture.</p>
<p>So we&#39;ll begin by getting the <code>Texture</code>, then we&#39;ll create a <code>TextureView</code> of that texture, then we&#39;ll create a <code>CommandEncoder</code> that let us create a <code>RenderPass</code> and finally we submit that render pass to the <code>Queue</code>:</p>
<pre><code class="language-rust">pub fn render(&amp;mut self, context: &amp;mut Context) -&gt; Result&lt;(), wgpu::SurfaceError&gt; {
  let output = context.surface().get_current_texture()?;

  let view = output
    .texture
    .create_view(&amp;wgpu::TextureViewDescriptor::default());

  let mut encoder =
    context
      .device()
      .create_command_encoder(&amp;wgpu::CommandEncoderDescriptor {
          label: Some(&quot;Render Encoder&quot;),
      });

  {
    let mut render_pass = encoder.begin_render_pass(&amp;wgpu::RenderPassDescriptor {
      label: Some(&quot;Render Pass&quot;),
      color_attachments: &amp;[Some(wgpu::RenderPassColorAttachment {
        view: &amp;view,
        resolve_target: None,
        ops: wgpu::Operations {
          load: wgpu::LoadOp::Clear(wgpu::Color {
            r: 0.0,
            g: 0.0,
            b: 0.4,
            a: 1.0,
          }),
          store: true,
        },
      })],
      depth_stencil_attachment: None,
    });
  }

  // submit will accept anything that implements IntoIter
  context.queue().submit(std::iter::once(encoder.finish()));
  output.present();

  Ok(())
}
</code></pre>
<p>You also have to specify what you want the render pass to do with the texture when it starts and when it ends:</p>
<p>A <code>load</code> value of <code>Clear</code> indicates that you want the texture to be cleared when the render pass starts.
A <code>store</code> value of <code>true</code> indicates that once the render pass is finished you want the results of any drawing done during the render pass saved into the texture.
Once the render pass has begun we do... nothing! At least for now. The act of starting the render pass with <code>load: Clear()</code> is enough to clear the texture view and the canvas.</p>
<p>You&#39;ve probably notice the extra block (<code>{}</code>) around <code>encoder.begin_render_pass()</code>. <code>begin_render_pass()</code> borrows <code>encoder</code> mutably. We can&#39;t call <code>encoder.finish()</code> until we release that mutable borrow. The block tells rust to drop any variables within it when the code leaves that scope thus releasing the mutable borrow on <code>encoder</code> and allowing us to <code>finish()</code> it. If you don&#39;t like the <code>{}</code>, you can also use <code>drop(render_pass)</code> to achieve the same effect.</p>
<p>Let&#39;s draw some triangles. Be warned now that it&#39;ll seem like a lot of work for such simple output, but that&#39;s because WebGPU is designed to render lots of geometry very efficiently. A side effect of this efficiency is that doing relatively simple things might feel unusually difficult, but that&#39;s the expectation if you&#39;re turning to an API like WebGPU—you want to do something a little more complex.</p>
<h2>Understand how GPUs draw</h2>
<p>Before any more code changes, it&#39;s worth doing a very quick, simplified, high-level overview of how GPUs create the shapes you see on screen.</p>
<p>Unlike an API like Pygame that has lots of shapes and options ready for you to use, your GPU really only deals with a few different types of shapes (or primitives as they&#39;re referred to by WebGPU): points, lines, and triangles. For the purposes of this lab you&#39;ll only use triangles.</p>
<p>GPUs work almost exclusively with triangles because triangles have a lot of nice mathematical properties that make them easy to process in a predictable and efficient way. Almost everything you draw with the GPU needs to be split up into triangles before the GPU can draw it, and those triangles must be defined by their corner points.</p>
<p>These points, or vertices, are given in terms of X, Y, and (for 3D content) Z values that define a point on a cartesian coordinate system defined by WebGPU or similar APIs. The structure of the coordinate system is easiest to think about in terms of how it relates to the surface on your window. No matter how wide or tall your canvas is, the left edge is always at -1 on the X axis, and the right edge is always at +1 on the X axis. Similarly, the bottom edge is always -1 on the Y axis, and the top edge is +1 on the Y axis. That means that (0, 0) is always the center of the canvas, (-1, -1) is always the bottom-left corner, and (1, 1) is always the top-right corner. This is known as <strong>Clip Space</strong>.</p>
<figure>
<img src="./clip_space.png" alt="">
</figure>

<p>The vertices are rarely defined in this coordinate system initially, so GPUs rely on small programs called vertex shaders to perform whatever math is necessary to transform the vertices into clip space, as well as any other calculations needed to draw the vertices. For example, the shader may apply some animation or calculate the direction from the vertex to a light source. These shaders are written by you, the WebGPU developer, and they provide an amazing amount of control over how the GPU works.</p>
<p>From there, the GPU takes all the triangles made up by these transformed vertices and determines which pixels on the screen are needed to draw them. Then it runs another small program you write called a fragment shader that calculates what color each pixel should be. That calculation can be as simple as return green or as complex as calculating the angle of the surface relative to sunlight bouncing off of other nearby surfaces, filtered through fog, and modified by how metallic the surface is. It&#39;s entirely under your control, which can be both empowering and overwhelming.</p>
<figure><img src="./Pipeline.svg" alt=""></figure>

<p>The results of those pixel colors are then accumulated into a texture, which is then able to be shown on screen.</p>
<h2>Define vertices</h2>
<p>As mentioned earlier, The Game of Life simulation is shown as a grid of cells. Your app needs a way to visualize the grid, distinguishing active cells from inactive cells. The approach used by this codelab will be to draw colored squares in the active cells and leave inactive cells empty.</p>
<p>This means that you&#39;ll need to provide the GPU with four different points, one for each of the four corners of the square. For example, a square drawn in the center of the canvas, pulled in from the edges a ways, has corner coordinates like this:</p>
<figure><img src="./vertices.png" alt=""></figure>

<p>In order to feed those coordinates to the GPU, you need to place the values in a Buffer. A buffer is a blob of data in the GPU memory. A buffer is guaranteed to be contiguous, meaning that all the data is stored sequentially in memory. Buffers are generally used to store simple things like structs or arrays, but they can store more complex stuff such as graph structures like trees (provided all the nodes are stored together and don&#39;t reference anything outside of the buffer). We are going to use buffers a lot, so let&#39;s get started with two of the most important ones: the vertex buffer, and the index buffer.</p>
<p>we are going to use buffers to store the vertex data we want to draw. Before we do that though we need to describe what a vertex looks like. We&#39;ll do this by creating a new struct in the <code>app.rs</code> file.</p>
<pre><code class="language-rust">#[repr(C)]
#[derive(Copy, Clone, Debug, bytemuck::Pod, bytemuck::Zeroable)]
struct Vertex {
    position: [f32; 2],
}
</code></pre>
<p>for now our vertices will just have a 2D position. WebGPU Buffer are just arrays of bytes (<code>&amp;[u8]</code>) so we will use the crate <code>bytemuck</code> to convert our array of <code>Vertex</code>. Let&#39;s add that dependency:</p>
<pre><code class="language-toml">bytemuck = { version = &quot;1.12&quot;, features = [ &quot;derive&quot; ] }
</code></pre>
<p>The two derives <code>Pod</code> and <code>Zeroable</code> make our <code>Vertex</code> struct castable by <code>bytemuck</code>.</p>
<p>Let&#39;s create the array of <code>Vertex</code> as a constant in the <code>app.rs</code> file:</p>
<pre><code class="language-rust">const VERTICES: &amp;[Vertex] = &amp;[
    Vertex {
        position: [-0.8, -0.8],
    },
    Vertex {
        position: [0.8, -0.8],
    },
    Vertex {
        position: [0.8, 0.8],
    },
    Vertex {
        position: [-0.8, -0.8],
    },
    Vertex {
        position: [0.8, 0.8],
    },
    Vertex {
        position: [-0.8, 0.8],
    },
];
</code></pre>
<p>This array is stored in the CPU memory. These 6 vertices describe the two triangles needed to draw our square. We arrange the vertices in counter-clockwise order: top, bottom left, bottom right. We do it this way partially out of tradition, but mostly because we will specify in the configuration of the render pipeline that we want the front face of our triangle to be <code>wgpu::FrontFace::Ccw</code> so that we cull the back face. This means that any triangle that should be facing us should have its vertices in counter-clockwise order.</p>
<p>Let&#39;s add a field to our <code>App</code> struct to store our buffer:</p>
<pre><code class="language-rust">pub struct App {
  vertex_buffer: wgpu::Buffer,
}
</code></pre>
<p>we will now create the buffer in the <code>new()</code> method:</p>
<pre><code class="language-rust">// needed for create_buffer_init
use wgpu::util::DeviceExt;

// in the App impl
pub fn new(context: &amp;mut Context) -&gt; Self {
  let vertex_buffer =
    context
      .device()
      .create_buffer_init(&amp;wgpu::util::BufferInitDescriptor {
        label: Some(&quot;Vertex Buffer&quot;),
        contents: bytemuck::cast_slice(VERTICES),
        usage: wgpu::BufferUsages::VERTEX,
      });

  Self {
    vertex_buffer,
  }
</code></pre>
<h2>Define the vertex layout</h2>
<p>Now you have a buffer with vertex data in it, but as far as the GPU is concerned it&#39;s just a blob of bytes. You need to supply a little bit more information if you&#39;re going to draw anything with it. You need to be able to tell WebGPU more about the structure of the vertex data.So we&#39;ll define the vertex data structure with a <code>VertexBufferLayout</code>:</p>
<pre><code class="language-rust">// in new()
let vertex_buffer_layout = wgpu::VertexBufferLayout {
  array_stride: std::mem::size_of::&lt;Vertex&gt;() as wgpu::BufferAddress,
  step_mode: wgpu::VertexStepMode::Vertex,
  attributes: &amp;[wgpu::VertexAttribute {
    offset: 0,
    shader_location: 0,
    format: wgpu::VertexFormat::Float32x2,
  }],
};
</code></pre>
<p>This can be a bit confusing at first glance, but it&#39;s relatively easy to break down.</p>
<p>The first thing you give is the <code>array_stride</code>. This is the number of bytes the GPU needs to skip forward in the buffer when it&#39;s looking for the next vertex. Each vertex of your square is made up of two 32-bit floating point numbers. As mentioned earlier, a 32-bit float is 4 bytes, so two floats is 8 bytes. Here we just use the size of a <code>Vertex</code> to get that value.</p>
<p>Next is the <code>attributes</code> field, which is an array. Attributes are the individual pieces of information encoded into each vertex. Your vertices only contain one attribute (the vertex position), but more advanced use cases frequently have vertices with multiple attributes in them like the color of a vertex or the direction the geometry surface is pointing. That&#39;s out of scope for this lab, though.</p>
<p>In your single attribute, you first define the format of the data. This comes from a list of <code>VertexFormat</code> types that describe each type of vertex data that the GPU can understand. Your vertices have two 32-bit floats each, so you use the format <code>float32x2</code>. If your vertex data is instead made up of four 16-bit unsigned integers each, for example, you&#39;d use <code>uint16x4</code> instead. See the pattern?</p>
<p>Next, the offset describes how many bytes into the vertex this particular attribute starts. You really only have to worry about this if your buffer has more than one attribute in it, which won&#39;t come up during this lab.</p>
<p>Finally, you have the <code>shader_location</code>. This is an arbitrary number between 0 and 15 and must be unique for every attribute that you define. It links this attribute to a particular input in the vertex shader, which you will learn about in the next section.</p>
<p>Notice that though you define these values now, you&#39;re not actually passing them into the WebGPU API anywhere just yet. That&#39;s coming up, but it&#39;s easiest to think about these values at the point that you define your vertices, so you&#39;re setting them up now for use later.</p>
<h2>Start with shaders</h2>
<p>Now you have the data you want to render, but you still need to tell the GPU exactly how to process it. A large part of that happens with shaders.</p>
<p>Shaders are small programs that you write and that execute on your GPU. Each shader operates on a different stage of the data: Vertex processing, Fragment processing, or general Compute. Because they&#39;re on the GPU, they are structured more rigidly than your average Rust. But that structure allows them to execute very fast and, crucially, in parallel!</p>
<p>Shaders in WebGPU are written in a shading language called WGSL (WebGPU Shading Language). WGSL is, syntactically, a bit like Rust, with features aimed at making common types of GPU work (like vector and matrix math) easier and faster. Teaching the entirety of the shading language is well beyond the scope of this lab, but hopefully you&#39;ll pick up some of the basics as you walk through some simple examples.</p>
<p>The shaders themselves get passed into WebGPU as strings.</p>
<pre><code class="language-rust">//in new()
let shader = context
  .device()
  .create_shader_module(wgpu::ShaderModuleDescriptor {
    label: Some(&quot;Shader&quot;),
    source: wgpu::ShaderSource::Wgsl(include_str!(&quot;shader.wgsl&quot;).into()),
  });
</code></pre>
<p>The <code>include_str!()</code> macro is executed during compilation and include the content of the <code>shader.wgsl</code> file as a string in the source of our program.</p>
<p>Here is the content of the <code>shader.wgsl</code> file:</p>
<pre><code class="language-rust">@vertex
fn vertexMain(@location(0) pos: vec2&lt;f32&gt;) -&gt; @builtin(position) vec4&lt;f32&gt; {
  return vec4(pos, 0.0, 1.0);
}

@fragment
fn fragmentMain() -&gt; @location(0) vec4&lt;f32&gt; {
  return vec4(1.0, 0.0, 0.0, 1.0);
}
</code></pre>
<p>This file contains two functions, one for the Vertex Stage and one for the Fragment Stage.</p>
<h2>The Vertex Shader</h2>
<p>Start with the vertex shader because that&#39;s where the GPU starts, too!</p>
<p>A vertex shader is defined as a function, and the GPU calls that function once for every vertex in your <code>vertex_buffer</code>. Since your <code>vertex_buffer</code> has six positions (vertices) in it, the function you define gets called six times. Each time it is called, a different position from the <code>vertex_buffer</code> is passed to the function as an argument, and it&#39;s the job of the vertex shader function to return a corresponding position in clip space.</p>
<p>It&#39;s important to understand that they won&#39;t necessarily get called in sequential order, either. Instead, GPUs excel at running shaders like these in parallel, potentially processing hundreds (or even thousands!) of vertices at the same time! This is a huge part of what&#39;s responsible for GPUs incredible speed, but it comes with limitations. In order to ensure extreme parallelization, vertex shaders cannot communicate with each other. Each shader invocation can only see data for a single vertex at a time, and is only able to output values for a single vertex.</p>
<p>In WGSL, a vertex shader function can be named whatever you want, but it must have the <code>@vertex</code> attribute in front of it in order to indicate which shader stage it represents.</p>
<p>A vertex shader must return at least the final position of the vertex being processed in clip space. This is always given as a 4-dimensional vector. Vectors are such a common thing to use in shaders that they&#39;re treated as first-class primitives in the language, with their own types like <code>vec4f</code> for a 4-dimensional vector. There are similar types for 2D vectors (<code>vec2f</code>) and 3D vectors (<code>vec3f</code>), as well! To indicate that the value being returned is the required position, it is marked with the @builtin(position) attribute.</p>
<p>As we want to make use of the data from the buffer that we created, we can declare an argument for the function with a @location() attribute and type that match what we described in the <code>vertex_buffer_layout</code>. We specified a <code>shader_location</code> of 0, so in our WGSL code, we mark the argument with <code>@location(0)</code>. We also defined the format as a <code>float32x2</code>, which is a 2D vector, so in WGSL our argument is a vec2f. We can name it whatever we like, but since these represent our vertex positions, a name like <code>pos</code> seems natural.</p>
<h2>The Fragment Shader</h2>
<p>Next up is the fragment shader. Fragment shaders operate in a very similar way to vertex shaders, but rather than being invoked for every vertex, they&#39;re invoked for every pixel being drawn.</p>
<p>Fragment shaders are always called after vertex shaders. The GPU takes the output of the vertex shaders and triangulates it, creating triangles out of sets of three points. It then rasterizes each of those triangles by figuring out which pixels of the output color attachments are included in that triangle, and then calls the fragment shader once for each of those pixels. The fragment shader returns a color, typically calculated from values sent to it from the vertex shader and assets like textures, which the GPU writes to the color attachment.</p>
<p>Just like vertex shaders, fragment shaders are executed in a massively parallel fashion. They&#39;re a little more flexible than vertex shaders in terms of their inputs and outputs, but you can consider them to simply return one color for each pixel of each triangle.</p>
<p>A WGSL fragment shader function is denoted with the <code>@fragment</code> attribute and it also returns a <code>vec4f</code>. In this case, though, the vector represents a color, not a position. The return value needs to be given a <code>@location</code> attribute in order to indicate which <code>color_attachment</code> from the <code>begin_render_pass</code> call the returned color is written to. Since you only had one attachment, the location is 0.</p>
<p>And that&#39;s a complete fragment shader! It&#39;s not a terribly interesting one; it just sets every pixel of every triangle to red, but that&#39;s sufficient for now.</p>
<h2>Create a render pipeline</h2>
<p>A shader module can&#39;t be used for rendering on its own. Instead, you have to use it as part of a <code>RenderPipeline</code>, created by calling <code>device.create_render_pipeline()</code>. The render pipeline controls how geometry is drawn, including things like which shaders are used, how to interpret data in vertex buffers, which kind of geometry should be rendered (lines, points, triangles...), and more!</p>
<p>The render pipeline is the most complex object in the entire API.</p>
<pre><code class="language-rust">// in new()
let render_pipeline =
  context
    .device()
    .create_render_pipeline(&amp;wgpu::RenderPipelineDescriptor {
      label: Some(&quot;Render Pipeline&quot;),
      layout: None, //Some(&amp;render_pipeline_layout),
      vertex: wgpu::VertexState {
        module: &amp;shader,
        entry_point: &quot;vertexMain&quot;,
        buffers: &amp;[vertex_buffer_layout],
      },
      fragment: Some(wgpu::FragmentState {
        module: &amp;shader,
        entry_point: &quot;fragmentMain&quot;,
        targets: &amp;[Some(wgpu::ColorTargetState {
          format: context.config().format,
          blend: Some(wgpu::BlendState::REPLACE),
          write_mask: wgpu::ColorWrites::ALL,
        })],
      }),
      primitive: wgpu::PrimitiveState {
        topology: wgpu::PrimitiveTopology::TriangleList,
        strip_index_format: None,
        front_face: wgpu::FrontFace::Ccw,
        cull_mode: Some(wgpu::Face::Back),
        // Setting this to anything other than Fill requires Features::NON_FILL_POLYGON_MODE
        polygon_mode: wgpu::PolygonMode::Fill,
        // Requires Features::DEPTH_CLIP_CONTROL
        unclipped_depth: false,
        // Requires Features::CONSERVATIVE_RASTERIZATION
        conservative: false,
      },
      depth_stencil: None,
      multisample: wgpu::MultisampleState {
        count: 1,
        mask: !0,
        alpha_to_coverage_enabled: false,
      },
      multiview: None,
    });
</code></pre>
<p>Every pipeline needs a <code>layout</code> that describes what types of inputs (other than vertex buffers) the pipeline needs, but we don&#39;t really have any. Fortunately, we can pass <code>None</code> for now, and the pipeline builds its own layout from the shaders.</p>
<p>Next, we have to provide details about the vertex stage. The module is the <code>ShaderModule</code> that contains your vertex shader, and the <code>entry_point</code> gives the name of the function in the shader code that is called for every vertex invocation. (We can have multiple @vertex and @fragment functions in a single shader module!) The buffers is an array of <code>VertexBufferLayout</code> objects that describe how our data is packed in the vertex buffers that we use this pipeline with. Luckily, we already defined this earlier in our <code>vertex_buffer_layout</code>! Here&#39;s where we pass it in.</p>
<p>Next, we have details about the fragment stage. This also includes a shader module and <code>entry_point</code>, like the vertex stage. The last bit is to define the targets that this pipeline is used with. This is an array of dictionaries giving details—such as the texture format—of the color attachments that the pipeline outputs to. These details need to match the textures given in the colorAttachments of any render passes that this pipeline is used with. Our render pass uses textures from the Surface, and uses the value we saved in the config of the Surface for its format, so we pass the same format here.</p>
<p>The <code>primitive</code> field describes how to interpret our vertices when converting them into triangles. Using <code>PrimitiveTopology::TriangleList</code> means that every three vertices will correspond to one triangle.</p>
<p>The <code>front_face</code> and <code>cull_mode</code> fields tell wgpu how to determine whether a given triangle is facing forward or not. <code>FrontFace::Ccw</code> means that a triangle is facing forward if the vertices are arranged in a counter-clockwise direction. Triangles that are not considered facing forward are culled (not included in the render) as specified by <code>CullMode::Back</code>.</p>
<p>The rest of the method is pretty simple:</p>
<ul>
<li>We&#39;re not using a depth/stencil buffer currently, so we leave <code>depth_stencil</code> as <code>None</code>.</li>
<li>count determines how many samples the pipeline will use. Multisampling is a complex topic, so we won&#39;t get into it here.</li>
<li><code>mask</code> specifies which samples should be active. In this case, we are using all of them.</li>
<li><code>alpha_to_coverage_enabled</code> has to do with anti-aliasing. We&#39;re not covering anti-aliasing here, so we&#39;ll leave this as <code>false</code> now.</li>
<li><code>multiview</code> indicates how many array layers the render attachments can have. We won&#39;t be rendering to array textures so we can set this to <code>None</code>.</li>
</ul>
<p>We will need this <code>render_pipeline</code> in our <code>render()</code> method so we have to add it as a field of our <code>App</code> struct. We will also need the number of vertices so we will add this as well:</p>
<pre><code class="language-rust">pub struct App {
  vertex_buffer: wgpu::Buffer,
  render_pipeline: wgpu::RenderPipeline,
  num_vertices: u32,
}

impl App {
  pub fn new(context: &amp;mut Context) -&gt; Self {
    // ...

    let num_vertices = VERTICES.len() as u32;

    Self {
      vertex_buffer,
      render_pipeline,
      num_vertices,
    }
  }

  // ...
}
</code></pre>
<h2>Draw the square</h2>
<p>And with that, you now have everything that you need in order to draw your square!</p>
<pre><code class="language-rust">{
  let mut render_pass = encoder.begin_render_pass(
    // ...
  );

  // 3 new lines
  render_pass.set_pipeline(&amp;self.render_pipeline);
  render_pass.set_vertex_buffer(0, self.vertex_buffer.slice(..));
  render_pass.draw(0..self.num_vertices, 0..1);
}
</code></pre>
<p>This supplies WebGPU with all the information necessary to draw your square. First, we use <code>set_pipeline()</code> to indicate which pipeline should be used to draw with. This includes the shaders that are used, the layout of the vertex data, and other relevant state data.</p>
<p>Next, we call <code>set_vertex_buffer()</code> with the buffer containing the vertices for your square. You call it with 0 because this buffer corresponds to the 0th element in the current pipeline&#39;s <code>vertex.buffers</code> definition.</p>
<p>And last, you make the <code>draw()</code> call, which seems strangely simple after all the setup that&#39;s come before. The only things you need to pass in is a range of vertices that it should render. The second parameter is a range of instance, we only draw one instance.</p>
<p>If we run the program now, we should see a big red rectangle.</p>
<figure><img src="./red_rectangle.png" alt=""></figure>

<p>First, take a moment to congratulate yourself! Getting the first bits of geometry on screen is often one of the hardest steps with most GPU APIs. Everything you do from here can be done in smaller steps, making it easier to verify your progress as you go.</p>
<h2>Define the grid</h2>
<p>In order to render a grid, you need to know a very fundamental piece of information about it. How many cells does it contain, both in width and height? This is up to you as the developer, but to keep things a bit easier, treat the grid as a square (same width and height) and use a size that&#39;s a power of two. (That makes some of the math easier later.) You want to make it bigger eventually, but for the rest of this section, set your grid size to 4x4 because it makes it easier to demonstrate some of the math used in this section. Scale it up after!</p>
<pre><code class="language-rust">// in app.rs
const GRID_SIZE: u32 = 4;
</code></pre>
<p>Next, you need to update how you render your square so that you can fit <code>GRID_SIZE</code> times <code>GRID_SIZE</code> of them on the canvas. That means the square needs to be a lot smaller, and there needs to be a lot of them.</p>
<p>Now, one way you could approach this is by making your vertex buffer significantly bigger and defining <code>GRID_SIZE</code> times <code>GRID_SIZE</code> worth of squares inside it at the right size and position. The code for that wouldn&#39;t be too bad, in fact! Just a couple of for loops and a bit of math. But that&#39;s also not making the best use of the GPU and using more memory than necessary to achieve the effect. This section looks at a more GPU-friendly approach.</p>
<h2>Create a uniform buffer</h2>
<p>First, you need to communicate the grid size you&#39;ve chosen to the shader, since it uses that to change how things display. You could just hard-code the size into the shader, but then that means that any time you want to change the grid size you have to re-create the shader and render pipeline, which is expensive. A better way is to provide the grid size to the shader as uniforms.</p>
<p>You learned earlier that a different value from the vertex buffer is passed to every invocation of a vertex shader. A uniform is a value from a buffer that is the same for every invocation. They&#39;re useful for communicating values that are common for a piece of geometry (like its position), a full frame of animation (like the current time), or even the entire lifespan of the app (like a user preference).</p>
<pre><code class="language-rust">// in App.new()
let uniform_array = [GRID_SIZE, GRID_SIZE];
let uniform_buffer =
  context
    .device()
    .create_buffer_init(&amp;wgpu::util::BufferInitDescriptor {
      label: Some(&quot;Uniform Buffer&quot;),
      contents: bytemuck::cast_slice(&amp;uniform_array),
      usage: wgpu::BufferUsages::UNIFORM,
    });
</code></pre>
<h2>Access uniforms in a shader</h2>
<pre><code class="language-rust">// At the top of shader.wgsl
@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;

@vertex
fn vertexMain(@location(0) pos: vec2f) -&gt;
  @builtin(position) vec4f {
  return vec4f(pos / grid, 0.0, 1.0);
}

// ...fragmentMain is unchanged
</code></pre>
<p>This defines a uniform in your shader called <code>grid</code>, which is a 2D float vector that matches the array that you just copied into the uniform buffer. It also specifies that the uniform is bound at <code>@group(0)</code> and <code>@binding(0)</code>. You&#39;ll learn what those values mean in a moment.</p>
<p>Then, elsewhere in the shader code, you can use the grid vector however you need. In this code you divide the vertex position by the grid vector. Since <code>pos</code> is a 2D vector and <code>grid</code> is a 2D vector, WGSL performs a component-wise division. In other words, the result is the same as saying <code>vec2f(pos.x / grid.x, pos.y / grid.y)</code>.</p>
<p>These types of vector operations are very common in GPU shaders since many rendering and compute techniques rely on them!</p>
<p>What this means in your case is that (if you used a grid size of 4) the square that you render would be one-fourth of its original size. That&#39;s perfect if you want to fit four of them to a row or column!</p>
<h2>Create a Bind Group</h2>
<p>Declaring the uniform in the shader doesn&#39;t connect it with the buffer that you created, though. In order to do that, you need to create and set a bind group.</p>
<p>A bind group is a collection of resources that you want to make accessible to your shader at the same time. It can include several types of buffers, like your uniform buffer, and other resources like textures and samplers that are not covered here but are common parts of WebGPU rendering techniques.</p>
<pre><code class="language-rust">// in App.new()
let bind_group = context
  .device()
  .create_bind_group(&amp;wgpu::BindGroupDescriptor {
    label: Some(&quot;Bind Group&quot;),
    layout: &amp;render_pipeline.get_bind_group_layout(0),
    entries: &amp;[wgpu::BindGroupEntry {
      binding: 0,
      resource: uniform_buffer.as_entire_binding(),
    }],
  });
</code></pre>
<p>In addition to your now-standard <code>label</code>, you also need a <code>layout</code> that describes which types of resources this bind group contains. This is something that you dig into further in a future step, but for the moment you can happily ask your pipeline for the bind group layout because you created the pipeline with <code>layout: None</code>. That causes the pipeline to create bind group layouts automatically from the bindings that you declared in the shader code itself. In this case, you ask it to <code>get_bind_group_layout(0)</code>, where the <code>0</code> corresponds to the <code>@group(0)</code> that you typed in the shader.</p>
<p>After specifying the layout, you provide an array of <code>entries</code>. Each entry is a dictionary with at least the following values:</p>
<ul>
<li><p><code>binding</code>, which corresponds with the <code>@binding()</code> value you entered in the shader. In this case, <code>0</code>.</p>
</li>
<li><p><code>resource</code>, which is the actual resource that you want to expose to the variable at the specified binding index. In this case, your uniform buffer.</p>
</li>
</ul>
<p>The function returns a <code>BindGroup</code>, which is an opaque, immutable handle. You can&#39;t change the resources that a bind group points to after it&#39;s been created, though you can change the contents of those resources. For example, if you change the uniform buffer to contain a new grid size, that is reflected by future draw calls using this bind group.</p>
<h2>Bind the bind group</h2>
<p>Now that the bind group is created, you still need to tell WebGPU to use it when drawing. To do that you need to access it in the <code>render()</code> method. So you must add it to our <code>App</code> struct.</p>
<pre><code class="language-rust">pub struct App {
    vertex_buffer: wgpu::Buffer,
    render_pipeline: wgpu::RenderPipeline,
    num_vertices: u32,
    bind_group: wgpu::BindGroup,   // new
}

impl App {
  pub fn new(context: &amp;mut Context) -&gt; Self {
    // ...
    
    Self {
      vertex_buffer,
      render_pipeline,
      num_vertices,
      bind_group,       // new
    }
  }
  // ...
  pub fn render(&amp;mut self, context: &amp;mut Context) -&gt; Result&lt;(), wgpu::SurfaceError&gt; {
    // ...
    {
      // ...
      render_pass.set_pipeline(&amp;self.render_pipeline);
      render_pass.set_vertex_buffer(0, self.vertex_buffer.slice(..));
      render_pass.set_bind_group(0, &amp;self.bind_group, &amp;[]);   // new
      render_pass.draw(0..self.num_vertices, 0..1);
    }
    // ...
  }
}
</code></pre>
<p>The <code>0</code> passed as the first argument corresponds to the<code> @group(0)</code> in the shader code. You&#39;re saying that each <code>@binding</code> that&#39;s part of <code>@group(0)</code> uses the resources in this bind group.</p>
<p>And now the uniform buffer is exposed to your shader!</p>
<figure><img src="./small_red_rect.png" alt=""></figure>

<p>Hooray! Your square is now one-fourth the size it was before! That&#39;s not much, but it shows that your uniform is actually applied and that the shader can now access the size of your grid.</p>
<h2>Manipulate geometry in the shader</h2>
<p>So now that you can reference the grid size in the shader, you can start doing some work to manipulate the geometry you&#39;re rendering to fit your desired grid pattern. To do that, consider exactly what you want to achieve.</p>
<p>You need to conceptually divide up your canvas into individual cells. In order to keep the convention that the X axis increases as you move right and the Y axis increases as you move up, say that the first cell is in the bottom left corner of the canvas. That gives you a layout that looks like this, with your current square geometry in the middle:</p>
<figure><img src="./grid.png" alt=""></figure>

<p>Your challenge is to find a method in the shader that lets you position the square geometry in any of those cells given the cell coordinates.</p>
<p>First, you can see that your square isn&#39;t nicely aligned with any of the cells because it was defined to surround the center of the canvas. You&#39;d want to have the square shifted by half a cell so that it would line up nicely inside them.</p>
<p>One way you could fix this is to update the square&#39;s vertex buffer. By shifting the vertices so that the bottom-right corner is at, for example, (0.1, 0.1) instead of (-0.8, -0.8), you&#39;d move this square to line up with the cell boundaries more nicely. But, since you have full control over how the vertices are processed in your shader, it&#39;s just as easy to simply nudge them into place using the shader code!</p>
<pre><code class="language-rust">@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;

@vertex
fn vertexMain(@location(0) pos: vec2f) -&gt;
  @builtin(position) vec4f {

  // Add 1 to the position before dividing by the grid size.
  let gridPos = (pos + 1.0) / grid;

  return vec4f(gridPos, 0.0, 1.0);
}
// ...
</code></pre>
<p>Since <code>pos</code> is a <code>vec2f</code> here, adding 1 does a component-wise addition. It&#39;s the same as saying <code>pos + vec2f(1, 1)</code>. The same works for subtraction, multiplication, and division!</p>
<p>This moves every vertex up and to the right by one (which, remember, is half of the clip space) before dividing it by the grid size. The result is a nicely grid-aligned square just off of the origin.</p>
<figure><img src="./grid1.png" alt=""></figure>

<p>Next, because your canvas&#39;s coordinate system places (0, 0) in the center and (-1, -1) in the lower left, and you want (0, 0) to be in the lower left, you need to translate your geometry&#39;s position by (-1, -1) after dividing by the grid size in order to move it into that corner.</p>
<pre><code class="language-rust">@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;

@vertex
fn vertexMain(@location(0) pos: vec2f) -&gt;
  @builtin(position) vec4f {

  // Subtract 1 after dividing by the grid size.
  let gridPos = (pos + 1.0) / grid - 1.0;

  return vec4f(gridPos, 0.0, 1.0); 
}
// ...
</code></pre>
<p>And now your square is nicely positioned in cell (0, 0)!</p>
<figure><img src="./grid2.png" alt=""></figure>

<p>What if you want to place it in a different cell? Figure that out by declaring a <code>cell</code> vector in your shader and populating it with a static value like <code>let cell = vec2f(1, 1)</code>.</p>
<p>And modify the shader to take <code>cell</code> into account:</p>
<pre><code class="language-rust">@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;

@vertex
fn vertexMain(@location(0) pos: vec2&lt;f32&gt;) -&gt; @builtin(position) vec4&lt;f32&gt; {
  let cell = vec2f(1.0, 1.0);
  let cellOffset = cell / grid * 2.0;
  let gridPos = (pos + 1.0) / grid - 1.0 + cellOffset;
  return vec4f(gridPos, 0.0, 1.0); 
}
</code></pre>
<p>And this gives you exactly what you want.</p>
<figure><img src="./grid3.png" alt=""></figure>

<p>Furthermore, you can now set cell to any value within the grid bounds, and then refresh to see the square render in the desired location.</p>
<h2>Draw instances</h2>
<p>Now that you can place the square where you want it with a bit of math, the next step is to render one square in each cell of the grid.</p>
<p>One way you could approach it is to write cell coordinates to a uniform buffer, then call draw once for each square in the grid, updating the uniform every time. That would be very slow, however, since the GPU has to wait for the new coordinate to be written by JavaScript every time. One of the keys to getting good performance out of the GPU is to minimize the time it spends waiting on other parts of the system!</p>
<p>Instead, you can use a technique called instancing. Instancing is a way to tell the GPU to draw multiple copies of the same geometry with a single call to <code>draw</code>, which is much faster than calling <code>draw</code> once for every copy. Each copy of the geometry is referred to as an instance.</p>
<pre><code class="language-rust">// update the draw call
render_pass.draw(0..self.num_vertices, 0..GRID_SIZE*GRID_SIZE);
</code></pre>
<p>This tells the system that you want it to draw the six (<code>0..self.num_vertices</code>) vertices of your square 16 (<code>0..GRID_SIZE * GRID_SIZE</code>) times. But if you refresh the page, you still see the following:</p>
<figure><img src="./red_rect_1_1.png" alt=""></figure>

<p>Why? Well, it&#39;s because you draw all 16 of those squares in the same spot. Your need to have some additional logic in the shader that repositions the geometry on a per-instance basis.</p>
<p>In the shader, in addition to the vertex attributes like <code>pos</code> that come from your vertex buffer, you can also access what are known as WGSL&#39;s built-in values. These are values that are calculated by WebGPU, and one such value is the <code>instance_index</code>. The <code>instance_index</code> is an unsigned 32-bit number from <code>0</code> to number of <code>instances - 1</code> that you can use as part of your shader logic. Its value is the same for every vertex processed that&#39;s part of the same instance. That means your vertex shader gets called six times with an <code>instance_index</code> of <code>0</code>, once for each position in your vertex buffer. Then six more times with an <code>instance_index</code> of <code>1</code>, then six more with <code>instance_index</code> of <code>2</code>, and so on.</p>
<p>To see this in action, you have to add the <code>instance_index</code> built-in to your shader inputs. Do this in the same way as the position, but instead of tagging it with a <code>@location</code> attribute, use <code>@builtin(instance_index)</code>, and then name the argument whatever you want. (You can call it <code>instance</code> to match the example code.) Then use it as part of the shader logic!</p>
<pre><code class="language-rust">@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;

@vertex
fn vertexMain(
  @location(0) pos: vec2&lt;f32&gt;,
  @builtin(instance_index) instance: u32
) -&gt; @builtin(position) vec4&lt;f32&gt; {
  let i = f32(instance);
  let cell = vec2f(i % grid.x, floor(i / grid.x));
  let cellOffset = cell / grid * 2.0;
  let gridPos = (pos + 1.0) / grid - 1.0 + cellOffset;
  return vec4f(gridPos, 0.0, 1.0); 
}
// ...
</code></pre>
<p>After making that update to the code you have the long-awaited grid of squares at last!</p>
<figure><img src="./red_squares.png" alt=""></figure>

<pre><code class="language-rust">const GRID_SIZE: u32 = 32;
</code></pre>
<figure><img src="./many_red_rect.png" alt=""></figure>

<p>Tada! You can actually make this grid really, really big now and your average GPU handles it just fine. You&#39;ll stop seeing the individual squares long before you run into any GPU performance bottlenecks.</p>
<p>To make our window square we can add this at the beginning of our <code>App.new()</code>.</p>
<pre><code class="language-rust">context
  .window()
  .set_inner_size(PhysicalSize::new(1200, 1200));
</code></pre>
<h2>Manage cell state</h2>
<p>Next, you need to control which cells on the grid render, based on some state that&#39;s stored on the GPU. This is important for the final simulation!</p>
<p>All you need is an on-off signal for each cell, so any options that allow you to store a large array of nearly any value type works. You might think that this is another use case for uniform buffers! While you <em>could</em> make that work, it&#39;s more difficult because uniform buffers are limited in size, can&#39;t support dynamically sized arrays (you have to specify the array size in the shader), and can&#39;t be written to by compute shaders. That last item is the most problematic, since you want to do the Game of Life simulation on the GPU in a compute shader.</p>
<p>Fortunately, there&#39;s another buffer option that avoids all of those limitations.</p>
<h2>Create a storage buffer</h2>
<p>Storage buffers are general-use buffers that can be read and written to in compute shaders, and read in vertex shaders. They can be very large, and they don&#39;t need a specific declared size in a shader, which makes them much more like general memory. That&#39;s what you use to store the cell state.</p>
<p><em>If storage buffers are so much more flexible, why bother with uniform buffers at all? It actually depends on your GPU hardware! There&#39;s a good chance that uniform buffers are given special treatment by your GPU in order to allow them to update and be read faster than a storage buffer, so for smaller amounts of data that have the potential to update frequently (like model, view, and projection matrices in 3D applications), uniforms are typically the safer choice for better performance.</em></p>
<p>To create a storage buffer for your cell state, use what—by now—is probably starting to be a familiar-looking snippet of buffer creation code:</p>
<pre><code class="language-rust">let cell_state_array = [0u32; (GRID_SIZE * GRID_SIZE) as usize];
  let cell_state_storage =
    context
      .device()
      .create_buffer_init(&amp;wgpu::util::BufferInitDescriptor {
        label: Some(&quot;Storage Buffer&quot;),
        contents: bytemuck::cast_slice(&amp;cell_state_array),
        usage: wgpu::BufferUsages::STORAGE,
      });
</code></pre>
<h2>Read the storage buffer in the shader</h2>
<p>Next, update your shader to look at the contents of the storage buffer before you render the grid. This looks very similar to how uniforms were added previously.</p>
<pre><code class="language-rust">@group(0) @binding(0) var&lt;uniform&gt; grid: vec2f;
@group(0) @binding(1) var&lt;storage&gt; cellState: array&lt;u32&gt;; // New!
</code></pre>
<p>First, you add the binding point, which tucks right underneath the grid uniform. You want to keep the same <code>@group</code> as the <code>grid</code> uniform, but the<code> @binding</code> number needs to be different. The <code>var</code> type is <code>storage</code>, in order to reflect the different type of buffer, and rather than a single vector, the type that you give for the cellState is an array of <code>u32</code> values, in order to match the <code>u32</code> in Rust.</p>
<p>Why 32 bit ints? Doesn&#39;t that seem wasteful if all you need are booleans? Well, yeah! It is! But also, the GPU only cleanly exposes data of a few types because it can work with them fast. You can&#39;t specify that you&#39;re exposing an array of bytes, for example, because it wouldn&#39;t work well with certain assumptions GPUs make about data alignment.</p>
<p>Now you could save space and use bitmasking tricks such as storing the active state for 32 different cells in each value of that array. There&#39;s actually a long history of developers finding clever ways to pack the data they need into GPU-approved types like that! But that would make the example code far more complex. And the truth is that for a use case as relatively simple as this one, you don&#39;t need to worry about the memory impact too much.</p>
<p>Next, in the body of your <code>@vertex</code> function, query the cell&#39;s state. Because the state is stored in a flat array in the storage buffer, you can use the <code>instance_index</code> in order to look up the value for the current cell!</p>
<p>How do you turn off a cell if the state says that it&#39;s inactive? Well, since the active and inactive states that you get from the array are 1 or 0, you can scale the geometry by the active state! Scaling it by 1 leaves the geometry alone, and scaling it by 0 makes the geometry collapse into a single point, which the GPU then discards.</p>
<pre><code class="language-rust">@vertex
fn vertexMain(
  @location(0) pos: vec2&lt;f32&gt;,
  @builtin(instance_index) instance: u32
) -&gt; @builtin(position) vec4&lt;f32&gt; {
  let i = f32(instance);
  let cell = vec2f(i % grid.x, floor(i / grid.x));
  let state = f32(cellState[instance]);
  let cellOffset = cell / grid * 2.0;
  let gridPos = (pos*state + 1.0) / grid - 1.0 + cellOffset;
  return vec4f(gridPos, 0.0, 1.0); 
}
</code></pre>
<h2>Add the storage buffer to the bind group</h2>
<p>Before you can see the cell state take effect, add the storage buffer to a bind group. Because it&#39;s part of the same <code>@group</code> as the uniform buffer, add it to the same bind group in the JavaScript code, as well.</p>
<pre><code class="language-rust">let bind_group = context
  .device()
  .create_bind_group(&amp;wgpu::BindGroupDescriptor {
    label: Some(&quot;Bind Group&quot;),
    layout: &amp;render_pipeline.get_bind_group_layout(0),
    entries: &amp;[
      wgpu::BindGroupEntry {
        binding: 0,
        resource: uniform_buffer.as_entire_binding(),
      },
      wgpu::BindGroupEntry {
        binding: 1,
        resource: cell_state_storage.as_entire_binding(),
      },
    ],
  });
</code></pre>
<p>Make sure that the binding of the new entry matches the <code>@binding()</code> of the corresponding value in the shader!</p>
<p>If you run it now, you will see no cell because we initialized all cell state to 0.</p>
<h2>Use the ping-pong buffer pattern</h2>
<p>Most simulations like the one you&#39;re building typically use at least two copies of their state. On each step of the simulation, they read from one copy of the state and write to the other. Then, on the next step, flip it and read from the state they wrote to previously. This is commonly referred to as a ping pong pattern because the most up-to-date version of the state bounces back and forth between state copies each step.</p>
<p>Why is that necessary? Look at a simplified example: imagine that you&#39;re writing a very simple simulation in which you move any active blocks right by one cell each step. To keep things easy to understand, you define your data and simulation in JavaScript:</p>
<pre><code class="language-javascript">// Example simulation. Don&#39;t copy into the project!
const state = [1, 0, 0, 0, 0, 0, 0, 0];

function simulate() {
  for (let i = 0; i &lt; state.length-1; ++i) {
    if (state[i] == 1) {
      state[i] = 0;
      state[i+1] = 1;
    }
  }
}

simulate(); // Run the simulation for one step.
</code></pre>
<p>But if you run that code, the active cell moves all the way to the end of the array in one step! Why? Because you keep updating the state in-place, so you move the active cell right, and then you look at the next cell and... hey! It&#39;s active! Better move it to the right again. The fact that you change the data at the same time that you observe it corrupts the results.</p>
<p>By using the ping pong pattern, you ensure that you always perform the next step of the simulation using only the results of the last step.</p>
<pre><code class="language-javascript">// Example simulation. Don&#39;t copy into the project!
const stateA = [1, 0, 0, 0, 0, 0, 0, 0];
const stateB = [0, 0, 0, 0, 0, 0, 0, 0];

function simulate(in, out) {
  out[0] = 0;
  for (let i = 1; i &lt; in.length; ++i) {
     out[i] = in[i-1];
  }
}

// Run the simulation for two step.
simulate(stateA, stateB);
simulate(stateB, stateA);
</code></pre>
<p>Use this pattern in your own code by updating your storage buffer allocation in order to create two identical buffers. To help visualize the difference between the two buffers, fill them with different data:</p>
<pre><code class="language-rust">let cell_state_array = [
  [0u32; (GRID_SIZE * GRID_SIZE) as usize],
  [1u32; (GRID_SIZE * GRID_SIZE) as usize],
];
let cell_state_storage = [
  context
    .device()
    .create_buffer_init(&amp;wgpu::util::BufferInitDescriptor {
      label: Some(&quot;Storage Buffer Ping&quot;),
      contents: bytemuck::cast_slice(&amp;cell_state_array[0]),
      usage: wgpu::BufferUsages::STORAGE,
    }),
  context
    .device()
    .create_buffer_init(&amp;wgpu::util::BufferInitDescriptor {
      label: Some(&quot;Storage Buffer Pong&quot;),
      contents: bytemuck::cast_slice(&amp;cell_state_array[1]),
      usage: wgpu::BufferUsages::STORAGE,
    }),
];
</code></pre>
<p>To show the different storage buffers in your rendering, update your bind groups to have two different variants, as well:</p>
<pre><code class="language-rust">let bind_group = [
  context
    .device()
    .create_bind_group(&amp;wgpu::BindGroupDescriptor {
        label: Some(&quot;Bind Group Ping&quot;),
        layout: &amp;render_pipeline.get_bind_group_layout(0),
        entries: &amp;[
          wgpu::BindGroupEntry {
            binding: 0,
            resource: uniform_buffer.as_entire_binding(),
          },
          wgpu::BindGroupEntry {
            binding: 1,
            resource: cell_state_storage[0].as_entire_binding(),
          },
        ],
    }),
  context
    .device()
    .create_bind_group(&amp;wgpu::BindGroupDescriptor {
      label: Some(&quot;Bind Group Pong&quot;),
      layout: &amp;render_pipeline.get_bind_group_layout(0),
      entries: &amp;[
        wgpu::BindGroupEntry {
          binding: 0,
          resource: uniform_buffer.as_entire_binding(),
        },
        wgpu::BindGroupEntry {
          binding: 1,
          resource: cell_state_storage[1].as_entire_binding(),
        },
      ],
    }),
];
</code></pre>
<p>You also need to update the definition of the struct:</p>
<pre><code class="language-rust">pub struct App {
  vertex_buffer: wgpu::Buffer,
  render_pipeline: wgpu::RenderPipeline,
  num_vertices: u32,
  bind_group: [wgpu::BindGroup; 2],
}
</code></pre>
<h2>Set up a timer</h2>
<p>We must now make our app change bind group every half second for example:</p>
<pre><code class="language-rust">use std::time::{Duration, Instant};
// ...

pub struct App {
  vertex_buffer: wgpu::Buffer,
  render_pipeline: wgpu::RenderPipeline,
  num_vertices: u32,
  bind_group: [wgpu::BindGroup; 2],
  step: u32,
  generation_duration: Duration,
  last_generation: Instant,
}

impl App {
  pub fn new(context: &amp;mut Context) -&gt; Self {
    // ...
    Self {
        vertex_buffer,
        render_pipeline,
        num_vertices,
        bind_group,
        step: 0,
        generation_duration: Duration::new(0, 500_000_000),
        last_generation: Instant::now(),
    }
  }

  // ...

  pub fn update(&amp;mut self) {
    if self.last_generation + self.generation_duration &lt; Instant::now() {
      self.step += 1;
      self.last_generation = Instant::now();
    }
  }

  pub fn render(&amp;mut self, context: &amp;mut Context) -&gt; Result&lt;(), wgpu::SurfaceError&gt; {
    // ...
    render_pass.set_bind_group(0, &amp;self.bind_group[(self.step % 2) as usize], &amp;[]);
    // ...
  }
}
</code></pre>
<p>And now when you run the app you see that the canvas flips back and forth between showing the two state buffers you created.</p>
<p>With that, you&#39;re pretty much done with the rendering side of things! You&#39;re all set to display the output of the Game of Life simulation you build in the next step, where you finally start using compute shaders.</p>
<p>Obviously there is so much more to WebGPU&#39;s rendering capabilities than the tiny slice that you explored here, but the rest is beyond the scope of this lab. Hopefully, it gives you enough of a taste of how WebGPU&#39;s rendering works, though, that it helps make exploring more advanced techniques like 3D rendering easier to grasp.</p>
<h2>Use compute shaders, at last!</h2>
<p>Now, for the last major piece of the puzzle: performing the Game of Life simulation in a compute shader!</p>
<p>You&#39;ve learned abstractly about compute shaders throughout this codelab, but what exactly are they?</p>
<p>A compute shader is similar to vertex and fragment shaders in that they are designed to run with extreme parallelism on the GPU, but unlike the other two shader stages, they don&#39;t have a specific set of inputs and outputs. You are reading and writing data exclusively from sources you choose, like storage buffers. This means that instead of executing once for each vertex, instance, or pixel, you have to tell it how many invocations of the shader function you want. Then, when you run the shader, you are told which invocation is being processed, and you can decide what data you are going to access and which operations you are going to perform from there.</p>
<p>Compute shaders must be created in a shader module, just like vertex and fragment shaders, so add that to your code to get started. As you might guess, given the structure of the other shaders that you&#39;ve implemented, the main function for your compute shader needs to be marked with the <code>@compute</code> attribute.</p>
<h2>Credits</h2>
<ul>
<li><a href="https://codelabs.developers.google.com/your-first-webgpu-app">&quot;Your first WebGPU app&quot; Codelab</a></li>
<li><a href="https://sotrh.github.io/learn-wgpu/">Learn Wgpu</a></li>
<li><a href="https://surma.dev/things/webgpu/">WebGPU — All of the cores, none of the canvas</a></li>
</ul>
<script>
    let show = true

    function init() {
        document.body.style.backgroundSize = "100%"
        document.body.style.imageRendering = "pixelated"
        const width = 40
        const height = 80
        const cellSize = 10
        const canvas = document.createElement("canvas")
        canvas.width = width*cellSize
        canvas.height = height*cellSize

        let context = undefined
        if (canvas.getContext) {
            context = canvas.getContext('2d')
        }

        return {
            canvas,
            width,
            height,
            context,
            cellSize
        }
    }

    function setPixel(x, y, state, ctx) {
        if(state)
        {
            ctx.context.fillStyle = "rgba(128, 128, 128, 0.15)"
            ctx.context.fillRect( x*ctx.cellSize, y*ctx.cellSize, ctx.cellSize, ctx.cellSize )
        }
    }

    function drawWorld(world, ctx) {
        ctx.canvas.width = ctx.canvas.width
        if(!show) return
        for(let x=0; x<ctx.width; x++) {
            for(let y=0; y<ctx.height; y++) {
                setPixel(x, y, world[x][y], ctx)
            }
        }
    }

    function countNeighbor(world, x, y, ctx) {
        function mod(n, d) {
            return ((n % d) + d) % d
        }

        function get(x, y) {
            return world[mod(x, ctx.width)][mod(y, ctx.height)]
        }

        let count = 0
        for(let X=x-1; X<=x+1; X++)
            for(let Y=y-1; Y<=y+1; Y++)
                if(X != x || Y != y)
                    if(get(X, Y))
                        count++
        return count
    }

    function createGrid(ctx) {
        grid = []
        for(let x=0; x<ctx.width; x++) {
            grid.push([])
            for(let y=0; y<ctx.height; y++) {
                grid[x].push(Math.random()>0.5 ? true : false)
            }
        }
        return grid
    }

    function next(cur, prev, ctx) {
        for(let x=0; x<ctx.width; x++) {
            for(let y=0; y<ctx.height; y++) {
                const neighbor = countNeighbor(prev, x, y, ctx)
                const alive = prev[x][y]
                if(alive) {
                    if(neighbor == 2 || neighbor == 3) cur[x][y] = true
                    else cur[x][y] = false
                }
                else {
                    if(neighbor == 3) cur[x][y] = true
                    else cur[x][y] = false
                }
            }
        }
        drawWorld(cur, ctx)
        document.body.style.backgroundImage = `url('${ctx.canvas.toDataURL()}')`;
        setTimeout(() => { next(prev, cur, ctx) }, 500)
    }

    function main() {
        const ctx = init()
        next(createGrid(ctx), createGrid(ctx), ctx)
        window.addEventListener('keypress', event => {
          if(event.key === 'h') {
            show = !show
          }
        })
    }

    main()
</script>

</body>
</html>
