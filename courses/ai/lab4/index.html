<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>AI5L - Super Sampling</title>
	<script src="https://quentin.lurkin.xyz/document.js"></script>
</head>
<body>
	<h1>AI5L - Super Sampling <small>Generative Adversarial Network</small></h1>
	<h2>Generative Adversarial Network</h2>
	<p>A Generative Adversarial Network (GAN) is a special train setup for making models that can generate data (images, text, ...). In this setup, two models opposes each other:</p>
	<ul>
		<li>the generator model get random noise as input and the desirable generated data as output,</li>
		<li>the discriminator model get a mix of real data and generated data as input and must classify them accordingly.</li>
	</ul>
	<p>The opposition between the models lies in the fact that the loss function of the generator get low values if it can generate data that are misclassified as real by the discriminator.</p>

	<p>The generator therefore trains to become better at generating data that looks like real data. Meanwhile the discriminator train to get better at detecting fake data.</p>

	<p><a href="https://www.tensorflow.org/tutorials/generative/dcgan">Here is a simple example of a GAN with Tensorflow and the MNIST Dataset.</a></p>
	<figure>
		<img src="./dcgan.gif" alt="" style='width: 40%'>
		<img src="./output.gif" alt="" style='width: 40%'>
	</figure>

	<h2>Super Sampling</h2>
	<p>The purpose of Super Sampling is to upscale images. This is traditionally done by linear or bicubic interpolation with low perceptual quality results.</p>
	<figure>
		<img src="./result.png" alt="">
	</figure>
	<p>With these traditional method, the produced images lacks of high frequency details because these details are not present in the low resolution input images.</p>

	<p>To produce high quality result with high frequency details, these details must be generated. This is where the GAN comes into play.</p>

	<p>In this problem, the generator will not produce the output from random noise. It will do it from the low resolution input image. Therefore, his loss function will be composed of two parts. An adversarial part that involve a discriminator model. And a content part that ensure that the content of the original image is retained.</p>

	<p><a href="./Photo-Realistic Single Image Super-Resolution Using a Generative Adversial Network.pdf">Here is a paper about such a GAN based Super Sampling Method.</a></p>

	<h2>Your Work</h2>
	<p>Use the method found in the paper above to create a program that can upscale images. You can use the <a href="https://data.vision.ee.ethz.ch/cvl/DIV2K/">DIV2K Dataset</a>.</p>
	<p>Because training can be very long we encourage you <a href="https://www.tensorflow.org/tensorboard/get_started">to monitor your training with <code>tf.summary</code> and Tensorboard</a>. It can help to cancel unsuccessful training and not waste time.</p>
	<p>An other helpful thing to do is saving checkpoints during training to be able to resume when interrupted (Example in the GAN MNIST link above).</p>
	<p>This work must be submitted on Claco for the 14th of may 11h59 PM.</p>

	<h2>Advices</h2>
	<ul>
		<li>The discriminator model presented in the paper need a lot of memory to run. You may have to scale it down significantly.
			<figure>
				<img src="./discriminator.png" alt="">
			</figure>
		</li>
		<li>Upscaling blocks of the generator can be replaced by <code>Conv2DTranspose</code> layers.</li>
		<li>To help with memory consumption, train with small image sizes (upscale 64x64 to 256x256 for example). You can also reduce the size of your batch.</li>
		<li>TensorFlow contains utilities to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory">load image datasets</a>.</li>
		<li>As mentioned above, checkpoints are useful to resume training. You can, for example, train your model during multiple nights and use your computer normally during daytime. TensorFlow contains <a href="https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager">Checkpoint Manager</a> that facilitate the use of checkpoints.</li>
		<li>At the end of training you can <a href="https://www.tensorflow.org/guide/keras/save_and_serialize">save</a> your generator to use it in an other python script.</li>
	</ul>
</body>
</html>